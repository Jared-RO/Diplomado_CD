{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/DCDPUAEM/DCDP/blob/main/03%20Machine%20Learning/notebooks/06-Practica-02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ],
      "metadata": {
        "id": "pBuAEgsFmC-e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Práctica 2: Clasificación\n",
        "\n",
        "En esta notebook resolveremos una práctica de clasificación donde probaremos varios clasificadores, el uso de gridseach. Además, nos enfrentaremos a varios desafios como son el desbalanceo de clases y el tamaño del dataset."
      ],
      "metadata": {
        "id": "vmWhZfIxi6yU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "glVe2E6ySpTP"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El siguiente es un datset de Kaggle.\n",
        "\n",
        "**Contexto**\n",
        "\n",
        "Los conjuntos de datos contienen transacciones realizadas con tarjetas de crédito en septiembre de 2013 por titulares de tarjetas europeos. Este conjunto de datos presenta transacciones que ocurrieron en dos días, donde tenemos 492 fraudes de 284,807 transacciones. El conjunto de datos está altamente desequilibrado, la clase positiva (fraudes) representa el 0.172% de todas las transacciones.\n",
        "\n",
        "Contiene solo variables de entrada numéricas que son el resultado de una transformación PCA. Desafortunadamente, debido a problemas de confidencialidad, no se pueden obtener las características originales y más información de fondo sobre los datos. Las características $V_1$, $V_2$, ..., $V_{28}$ son los componentes principales obtenidos con PCA, las únicas características que no se han transformado con PCA son 'Tiempo' y 'Cantidad'. La función 'Tiempo' contiene los segundos transcurridos entre cada transacción y la primera transacción en el conjunto de datos. La característica 'Cantidad' es la Cantidad de la transacción, esta característica se puede utilizar para el aprendizaje sensible al costo dependiente del ejemplo. La característica 'Clase' es la variable de respuesta y toma el valor 1 en caso de fraude y 0 en caso contrario.\n",
        "\n",
        "\n",
        "Recordemos las buenas prácticas del Machine Learning: https://scikit-learn.org/stable/common_pitfalls.html"
      ],
      "metadata": {
        "id": "-cCQM40V_dJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/DCDPUAEM/DCDP/raw/main/03%20Machine%20Learning/data/creditcard.zip"
      ],
      "metadata": {
        "id": "Pn3e7vxXgDyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip creditcard.zip"
      ],
      "metadata": {
        "id": "rhZTN5RPgcKO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "credito = pd.read_csv(\"creditcard.csv\")"
      ],
      "metadata": {
        "id": "8AGYagMwh8GI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "credito.head()"
      ],
      "metadata": {
        "id": "60RwWl3OAM7y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "credito.describe()"
      ],
      "metadata": {
        "id": "xb2G0chpAP-c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "# Graficamos los que no son fraude\n",
        "time_amount = credito[credito['Class'] == 0][['Time','Amount']].values\n",
        "plt.scatter(time_amount[:,0], time_amount[:,1],\n",
        "            c='green',alpha=0.25,label='Clean')\n",
        "# Graficamos los que sí son fraude\n",
        "time_amount = credito[credito['Class'] == 1][['Time','Amount']].values\n",
        "plt.scatter(time_amount[:,0], time_amount[:,1],\n",
        "            c='red',label='Fraud',marker='x')\n",
        "plt.legend(loc='best')\n",
        "plt.title('Amount vs fraud')\n",
        "plt.xlabel('Time', fontsize=16)\n",
        "plt.ylabel('Amount', fontsize=16)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dId7E_NrAXAt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "\n",
        "plt.figure()\n",
        "sns.countplot(x = \"Class\", data = credito)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rHQqW8EqAbW1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "No_of_frauds = credito[credito[\"Class\"]==1].shape[0]\n",
        "No_of_normals = credito[credito[\"Class\"]==0].shape[0]\n",
        "print(\"Hay {} transacciones normales (clase 0)\".format(No_of_normals))\n",
        "print(\"Hay {} transacciones fraudulentas (clase 1)\".format(No_of_frauds))\n",
        "total = No_of_frauds + No_of_normals\n",
        "pf= (No_of_frauds / total)*100\n",
        "pn= (No_of_normals / total)*100\n",
        "print(\"Porcentaje clase 0 = {}%\".format(np.round(pn,2)))\n",
        "print(\"Porcentaje clase 1 = {}%\".format(np.round(pf,2)))"
      ],
      "metadata": {
        "id": "OaWkLhQvBLKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFExW0e-20l7"
      },
      "source": [
        "### Submuestro\n",
        "\n",
        "Se necesita hacer un submuestreo para balancear las clases\n",
        "\n",
        "* Está claro que la Clase 1 está subrepresentada ya que solo  representa el 0.17% de todo el conjunto de datos.\n",
        "* Si entrenamos nuestro modelo usando este conjunto de datos, el modelo será ineficiente y será entrenado para predecir solo la Clase 0 porque no tendrá suficientes datos de entrenamiento.\n",
        "* Podemos obtener una alta exactitud al probar el modelo, pero no debemos confundirnos con esto porque nuestro conjunto de datos no tiene datos de prueba equilibrados. Por lo tanto, tenemos que confiar en el recall que se basa en TP y FP.\n",
        "* En los casos en que tengamos datos asimétricos, agregar datos adicionales de la característica subrepresentada (sobremuestreo) es una opción, mediante la modelación de la distribución de los datos. Por ahora no tenemos esa opción, así que tendremos que recurrir al submuestreo.\n",
        "* El submuestreo del conjunto de datos implica mantener todos nuestros datos subrepresentados (Clase 1) mientras se muestrea el mismo número de características de la Clase 0 para crear un nuevo conjunto de datos que comprenda una representación igual de ambas clases."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MucsJV0r20l7"
      },
      "source": [
        "Obtenemos un conjunto de datos más balanceado que contenga el doble de instancias no fraudulentas respecto a las fraudulentas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K4OPAV8M20l8"
      },
      "outputs": [],
      "source": [
        "# lista los índices de fraude del data set completo\n",
        "fraud_idxs = credito[credito[\"Class\"]==1].index.to_list()\n",
        "\n",
        "# lista de índices normales del data set completo\n",
        "normal_idxs = credito[credito[\"Class\"]==0].index.to_list()\n",
        "\n",
        "# seleccionamos aleatoriamente el doble de índices de transacciones normales que de normales\n",
        "random_normal_idxs = np.random.choice(normal_idxs, No_of_frauds*2, replace= False)\n",
        "\n",
        "# concatenamos los índices fraudulentos y normales y creamos el dataframe sub-sampleado\n",
        "undersampled_indices = np.concatenate([fraud_idxs, random_normal_idxs])\n",
        "undersampled_data = credito.iloc[undersampled_indices, :]\n",
        "\n",
        "print(f\"Fraude: {len(fraud_idxs)}, Normales: {len(random_normal_idxs)}\")\n",
        "undersampled_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6Wrm6M620l8"
      },
      "source": [
        "Comprobemos que los datos quedaron balanceados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_TRLcfkS20l9"
      },
      "outputs": [],
      "source": [
        "No_of_frauds_sampled = len(undersampled_data[undersampled_data[\"Class\"]== 1])\n",
        "\n",
        "No_of_normals_sampled = len(undersampled_data[undersampled_data[\"Class\"]== 0])\n",
        "\n",
        "print(\"Número de transacciones normales (clase 0): \", No_of_normals_sampled)\n",
        "print(\"Número de transacciones fraudulentas (clase 1): \", No_of_frauds_sampled)\n",
        "total_sampled = No_of_frauds_sampled + No_of_normals_sampled\n",
        "print(\"Número total de instancias: \", total_sampled)\n",
        "\n",
        "Fraud_percent_sampled = (No_of_frauds_sampled / total_sampled)*100\n",
        "Normal_percent_sampled = (No_of_normals_sampled / total_sampled)*100\n",
        "print(f\"Porcentaje clase 0: {round(Normal_percent_sampled,2)}\")\n",
        "print(f\"Porcentaje clase 1: {round(Normal_percent_sampled,2)}\")\n",
        "\n",
        "count_sampled = pd.value_counts(undersampled_data[\"Class\"], sort= True)\n",
        "count_sampled.plot(kind= 'bar')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# quitamos las columnas \"Time\" y \"Amount\"\n",
        "undersampled_data.drop([\"Time\"], axis= 1,inplace=True)"
      ],
      "metadata": {
        "id": "_7a2FuivMYhv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_PjO_td20l9"
      },
      "source": [
        "### Oversampling\n",
        "\n",
        "Ahora haremos un proceso llamado [SMOTE: Synthetic Minority Over-sampling Technique](https://arxiv.org/abs/1106.1813)\n",
        "\n",
        "\n",
        "Para ello necesitamos instalar la librería de _aprendizaje desequilibrado_ ``imbalanced-learn`` de Python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qa_Vb4NP20l_"
      },
      "outputs": [],
      "source": [
        "!pip install imbalanced-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos imprimir información sobre el módulo"
      ],
      "metadata": {
        "id": "ZuEXCTrtugUW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l4fPH1Bd20mA"
      },
      "outputs": [],
      "source": [
        "import imblearn\n",
        "print(imblearn.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WaNpF9Cu20mB"
      },
      "source": [
        "Obtenemos la matriz de datos $X$ y el vector de clases $y$ correspondiente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-fWtfSkU20mB"
      },
      "outputs": [],
      "source": [
        "X = undersampled_data.loc[:, undersampled_data.columns != \"Class\"].values\n",
        "y = undersampled_data.loc[:, undersampled_data.columns == \"Class\"].values\n",
        "\n",
        "print(f\"Matriz de features: {X.shape}\")\n",
        "print(f\"Matriz de etiquetas: {y.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EF4zrMIG20mC"
      },
      "source": [
        "Hagamos el proceso de sobre-muestreo [SMOTE](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTE.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qfmmO0By20mC"
      },
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "oversample = SMOTE()\n",
        "X_oversampled, y_oversampled = oversample.fit_resample(X, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nG7Hf5ix20mD"
      },
      "source": [
        "Verifiquemos la cantidad de datos ahora"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "print(f\"Matriz de features: {X_oversampled.shape}\")\n",
        "print(f\"Matriz de etiquetas: {y_oversampled.shape}\")\n",
        "\n",
        "print(Counter(y_oversampled))"
      ],
      "metadata": {
        "id": "NRujZ0ltPzEa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sb2gdqXw20mH"
      },
      "source": [
        "### Crear el conjunto de entrenamiento y prueba\n",
        "\n",
        "Separamos los datos en datos de entrenamiento (75%) y prueba (25%)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V3loC9tl20mH"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_oversampled, y_oversampled,\n",
        "                                                    test_size = 0.25,\n",
        "                                                    random_state = 359)\n",
        "\n",
        "print(f\"X_train: {len(X_train)}\")\n",
        "print(f\"X_test: {len(X_test)}\")\n",
        "print(f\"y_train: {len(y_train)}\")\n",
        "print(f\"y_test: {len(y_test)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTSJsp2K20mB"
      },
      "source": [
        "### Re-escalemos los datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SqtPP2k520mB"
      },
      "outputs": [],
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "sc = preprocessing.StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "\n",
        "X_test = sc.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5GqWW6Q20mH"
      },
      "source": [
        "⭕ Elige una SVM y entrénalo con un conjunto de parámetros de tu elección. Obtener el accuracy usando el método `score` del clasificador."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ekwgZfiG20mH"
      },
      "outputs": [],
      "source": [
        "classifier = SVC(C=1, kernel= 'rbf', random_state=0, gamma='scale')\n",
        "classifier.fit(X_train, y_train)\n",
        "classifier.score(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qp_YhOUu20mI"
      },
      "source": [
        "### Prueba el modelo\n",
        "\n",
        "Realiza las predicciones con el conjunto de prueba y bserva la matriz de confusión."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nTRsqljv20mI"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "y_pred = classifier.predict(X_test)\n",
        "CM = confusion_matrix(y_test, y_pred)\n",
        "print(CM)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "⭕ Calcula también el *F1-score* y el *precision score*"
      ],
      "metadata": {
        "id": "WGQVuXnXZdHd"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JjrOfFZ9Th4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRmyrMl720mK"
      },
      "source": [
        "### Aplica GridSearch para obtener los mejores parámetros para una SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PJEOf9L320mK"
      },
      "outputs": [],
      "source": [
        "parameters = [{'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n",
        "              {'C': [1, 10, 100, 1000], 'kernel': ['rbf'], 'gamma': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}\n",
        "              ]\n",
        "\n",
        "grid_search = GridSearchCV(estimator = classifier,\n",
        "                           param_grid = parameters,\n",
        "                           scoring = 'accuracy',\n",
        "                           cv = 5,\n",
        "                           n_jobs = -1)\n",
        "\n",
        "grid_search = grid_search.fit(X_train, y_train)\n",
        "best_accuracy = grid_search.best_score_\n",
        "print(\"The best accuracy using gridSearch is\", best_accuracy)\n",
        "\n",
        "best_parameters = grid_search.best_params_\n",
        "print(\"The best parameters for using this model is\", best_parameters)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfaYAhAK20mL"
      },
      "source": [
        "### Utiliza los mejores parámetros para probar de nuevo tu modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J9EpQKyf20mM"
      },
      "outputs": [],
      "source": [
        "classifier_with_best_parameters =  SVC(C= best_parameters[\"C\"],\n",
        "                                       kernel= best_parameters[\"kernel\"],\n",
        "                                       random_state= 0)\n",
        "classifier_with_best_parameters.fit(X_train, y_train)\n",
        "\n",
        "y_pred_best_parameters = classifier_with_best_parameters.predict(X_test)\n",
        "\n",
        "CM2 = confusion_matrix(y_test, y_pred_best_parameters)\n",
        "print(CM2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "⭕ Calcula las métricas de rendimiento: Accuracy, Recall, F1-score, Precision"
      ],
      "metadata": {
        "id": "rEJwIr5PVbX-"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-BBLmTOSbOSl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "htKoV-CNfgJA"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wgbaCD020mN"
      },
      "source": [
        "### ⭕ Práctica\n",
        "\n",
        "La práctica consiste en dos ejercicios:\n",
        "\n",
        "1. Usa el modelo anterior (**no lo vuelvas a entrenar**) para obtener las predicciones en todos el conjunto de datos original. Reporta las 4 métricas de rendimiento, así como la matriz de confusión. *Hint*: Puedes usar un pipeline para facilitar el proceso.\n",
        "\n",
        "2. Usa el clasificador lineal OLS con el conjunto de datos entrenamiento balanceado usado en la sesión (el de tamaño 1476). Reporta las 4 métricas de rendimiento, así como la matriz de confusión.\n",
        "\n",
        "3. Entrena un nuevo clasificador SVM en todo el conjunto sesgado.\n",
        "\n",
        "    3.1. Separa el conjunto completo en 75% de entrenamiento y 20% de prueba.\n",
        "\n",
        "    3.2. Entrena un nuevo modelo en este nuevo conjunto de entrenamiento y obten las predicciones en el conjunto de prueba.\n",
        "    \n",
        "    3.3 Reporta las 4 métricas de rendimiento, así como la matriz de confusión.\n",
        "    \n",
        "    Puedes usar técnicas de re-escalamiento, gridsearch, selección de features. Puedes usar un pipeline para facilitar el proceso.\n",
        "\n",
        "Redacta una conclusión comparando el desempeño de la parte 1 y la parte 3.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7y7HAzbbWOKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6moxfCAm20mP"
      },
      "source": [
        "___"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ⭕ **Ejercicio importante por tu cuenta**\n",
        "\n",
        "Prueba el modelo del ejercicio dos con varias modificaciones y revisamos en cada caso:\n",
        "1. El rendimiento (R2/MAE/MSE), ¿disminuye o aumenta?\n",
        "2. ¿Qué variables son las que son más importantes?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Cargamos la info:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "url = 'https://github.com/DCDPUAEM/DCDP/raw/main/03%20Machine%20Learning/data/cars-prices.csv'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Procesamos el dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "PzwYqd_qRLUx"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Entrenamiento: ((164, 45), (164,))\n",
            "Prueba: ((41, 45), (41,))\n"
          ]
        }
      ],
      "source": [
        "##PROCESAMIENTO\n",
        "#quitamos algunas variables no relevantes\n",
        "df = pd.read_csv(url)\n",
        "df.drop(columns=['car_ID','CarName'],inplace=True)\n",
        "\n",
        "# Reemplazar los datos de las columnas `cylindernumber` y `doornumber` con número. Las convertimos a variables numéricas\n",
        "cols = ['cylindernumber','doornumber']\n",
        "replacing_dict = {'four':4, 'six':6, 'five':5, 'three':3, 'twelve':12, 'two':2, 'eight':8}\n",
        "for col in cols:\n",
        "    df[col].replace(replacing_dict,inplace=True)\n",
        "\n",
        "#SEPARAMOS VARIABLES DE SALIDA\n",
        "y = df['price'].values\n",
        "df.drop(columns='price',inplace=True)\n",
        "\n",
        "#CODIGICACION ONE HOT PARA VARIABLES CATEGÓRICAS\n",
        "X_df = pd.get_dummies(df)\n",
        "\n",
        "#DEFINIMOS MATRIZ DE FEATURES\n",
        "X = X_df.values\n",
        "\n",
        "#Dividimos los datos en entrenamiento (train) y prueba (test) con una proporción 80%/20%.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, train_size=0.8, random_state=4595)\n",
        "print(f\"Entrenamiento: {X_train.shape,y_train.shape}\")\n",
        "print(f\"Prueba: {X_test.shape,y_test.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 1. *¿Qué pasa si no usas normalización?*\n",
        "\n",
        "* Probamos el modelo sin normalización:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "R2 entrenamiento [NO NORMALIZADO: 0.93, NORMALIZADOS: 0.93]\n",
            "R2 prueba [NO NORMALIZADO: 0.89, NORMALIZADOS: 0.89]\n",
            "\n",
            "MAE entrenamiento [NO NORMALIZADO: 1478.95, NORMALIZADOS:  1478.95]\n",
            "MAE prueba [NO NORMALIZADO: 2234.67, NORMALIZADOS: 2234.67]\n",
            "\n",
            "MSE entrenamiento [NO NORMALIZADO: 3692070.72, NORMALIZADOS: 3692070.72]\n",
            "MSE prueba [NO NORMALIZADO: 11944281.56, NORMALIZADOS: 11944281.56]\n",
            "\n",
            "Principales variables para determinar el precio con valores no normalizados: \n",
            "{'enginetype_rotor': 7769.116621714023, 'enginelocation_rear': 5703.189008174585, 'fuelsystem_idi': 5295.5601553045335, 'fueltype_diesel': 5295.560155304531, 'carbody_convertible': 2901.1564386774576}\n",
            "\n",
            "Principales variables para determinar el precio con valores normalizados: \n",
            "{'enginesize': 32482.93170169278, 'curbweight': 11712.045795038339, 'enginetype_rotor': 7769.116621714724, 'carwidth': 6676.770950541305, 'enginelocation_rear': 5703.189008173684}\n"
          ]
        }
      ],
      "source": [
        "selector = VarianceThreshold()\n",
        "X_train = selector.fit_transform(X_train)   # Entrenamos y transformamos el de entrenamiento\n",
        "X_test = selector.transform(X_test)        # Sólo transformamos el de prueba\n",
        "\n",
        "### NO REALIZAMOS LA NORMALIZACION PARA ESTOS DATOS\n",
        "lr_1 = LinearRegression()\n",
        "lr_1.fit(X_train, y_train)\n",
        "y_pred_test_1 = lr_1.predict(X_test)\n",
        "y_pred_train_1 = lr_1.predict(X_train)\n",
        "\n",
        "#CREAMOS COPIA PARA HACERLO CON DATOS NORMALIZADOS\n",
        "X_train_2=X_train.copy()\n",
        "X_test_2=X_test.copy()\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler = MinMaxScaler()\n",
        "X_train_2 = scaler.fit_transform(X_train_2)\n",
        "X_test_2 = scaler.transform(X_test_2)\n",
        "lr_2 = LinearRegression()\n",
        "lr_2.fit(X_train_2, y_train)\n",
        "\n",
        "y_pred_test_2 = lr_2.predict(X_test_2)\n",
        "y_pred_train_2 = lr_2.predict(X_train_2)\n",
        "\n",
        "#COMPARAMOS\n",
        "print(f'R2 entrenamiento [NO NORMALIZADO: {lr_1.score(X_train,y_train).round(2)}, NORMALIZADOS: {lr_2.score(X_train_2,y_train).round(2)}]')\n",
        "print(f'R2 prueba [NO NORMALIZADO: {lr_1.score(X_test,y_test).round(2)}, NORMALIZADOS: {lr_2.score(X_test_2,y_test).round(2)}]\\n')\n",
        "\n",
        "print(f\"MAE entrenamiento [NO NORMALIZADO: {mean_absolute_error(y_train,y_pred_train_1).round(2)}, NORMALIZADOS:  {mean_absolute_error(y_train,y_pred_train_2).round(2)}]\")  # Esta es muy interpretativa\n",
        "print(f\"MAE prueba [NO NORMALIZADO: {mean_absolute_error(y_test,y_pred_test_1).round(2)}, NORMALIZADOS: {mean_absolute_error(y_test,y_pred_test_2).round(2)}]\\n\")  # Esta es muy interpretativa\n",
        "\n",
        "print(f\"MSE entrenamiento [NO NORMALIZADO: {mean_squared_error(y_train,y_pred_train_1).round(2)}, NORMALIZADOS: {mean_squared_error(y_train,y_pred_train_2).round(2)}]\")\n",
        "print(f\"MSE prueba [NO NORMALIZADO: {mean_squared_error(y_test,y_pred_test_1).round(2)}, NORMALIZADOS: {mean_squared_error(y_test,y_pred_test_2).round(2)}]\\n\")\n",
        "\n",
        "\n",
        "columns = X_df.columns.to_list()\n",
        "coefs_dict = dict(zip(columns,lr_1.coef_))\n",
        "print(f'Principales variables para determinar el precio con valores no normalizados: \\n{dict(sorted(coefs_dict.items(),key=lambda x:x[1],reverse=True)[0:5])}\\n')\n",
        "\n",
        "columns = X_df.columns.to_list()\n",
        "coefs_dict = dict(zip(columns,lr_2.coef_))\n",
        "print(f'Principales variables para determinar el precio con valores normalizados: \\n{dict(sorted(coefs_dict.items(),key=lambda x:x[1],reverse=True)[0:5])}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Comentarios:**  \n",
        "Con estos resultados podemos observar que entre los valores normalizados y los no normalizados no hay una diferencia en los índices de rendimiento, pero si se ven afectadas las principales variables para determinar el valor del precio.  \n",
        "Con los datos no normalizados tenemos que **enginetype_rotor** y **enginelocation_rear** son las variables con mayor peso. Mientras que con los datos normalizados tenemos que son **enginesize** y **curbweight**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NRlo3s6Di2X"
      },
      "source": [
        "####  2. *¿Qué pasa si no haces selección de features? ¿qué pasa si sólo te quedas con algunas features seleccionadas *intuitivamente*?*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 3. *¿Qué pasa si no cuidas el data leakage? Es decir, haz primero todo el preprocesamiento y después divides en train/test.*\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ijVzcQ4DinD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkqMX7SVPsxO"
      },
      "source": [
        "Una pregunta que surge con frecuencia se refiere a la incertidumbre acerca de los parámetros del modelo, ya que estos también son variables aleatorias.\n",
        "\n",
        "En general, Scikit-Learn no proporciona herramientas para obtener conclusiones acerca de los parámetros internos del modelo: la interpretación de los parámetros del modelo es mucho más una *pregunta de modelaje estadístico* que una pregunta de *aprendizaje automático*. El aprendizaje automático se centra más la *predicción*.\n",
        "\n",
        "No obstante, si se desea profundizar en el significado de los parámetros del modelo, hay herramientas como las incluidas en el [paquete de Statsmodels de Python](http://statsmodels.sourceforge.net/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A4TID5B_XGui"
      },
      "outputs": [],
      "source": [
        "import statsmodels.api as sm\n",
        "\n",
        "X_train_1 = sm.add_constant(X_train)\n",
        "X_train_1_df = pd.DataFrame(X_train_1, columns=['const']+X_df.columns.to_list())\n",
        "display(X_train_1_df.head())\n",
        "results = sm.OLS(y_train, X_train_1_df).fit()\n",
        "print(results.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_iZumH9Q7Tv"
      },
      "source": [
        "**Algunas observaciones**\n",
        "\n",
        "* `R-squared` nos dice que nuestro modelo explica 93% del cambio en la variable dependiente (el precio del automovil).\n",
        "* `Adj. R-squared` ajusta el coeficiente `R-squared` tomando en cuenta el número de variables (features).\n",
        "* Los p-values `P>|t|` nos dice qué tan probable es que el coeficiente de la población haya sido medido por azar. Es decir, pone a prueba la hipótesis nula de que la variable independiente no tiene correlación con la variable dependiente. Hay dos escenarios:\n",
        "    * El valor es superior al nivel de significancia, no hay asociación entre los cambios en la variable independiente y los cambios en la variable dependiente. En otras palabras, no hay pruebas suficientes para concluir que existe un efecto a nivel de población.\n",
        "    * Si el valor p de una variable es inferior al nivel de significancia, los datos de la muestra proporcionan pruebas suficientes para rechazar la hipótesis nula de toda la población. Sus datos favorecen la hipótesis de que existe una correlación distinta de cero. Los cambios en la variable independiente están asociados a cambios en la variable dependiente a nivel poblacional. Esta variable es estadísticamente significativa y probablemente merezca la pena añadirla a su modelo de regresión."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YfxfQA4LYZ3c"
      },
      "source": [
        "## Ejemplo 3: Regularización\n",
        "\n",
        "La regularización es una técnica de regresión lineal que penaliza la magnitud de los coeficientes de la regresión. Los coeficientes minimizan una suma de cuadrados residual penalizada:\n",
        "\n",
        "$$\\text{min}_w \\|Xw - y \\|^2+α\\|w\\|^2$$\n",
        "\n",
        "El parámetro de complejidad $\\alpha>0$ controla la cantidad de contracción: cuanto mayor sea el valor de $\\alpha$, mayor será la cantidad de contracción.\n",
        "\n",
        "Hay tres tipos de regularización en la regresión:\n",
        "\n",
        "* [Ridge](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html): Es la descrita anteriormente.\n",
        "* [Lasso](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html): Es parecida a la anterior, pero usando la norma L1:\n",
        "    $$\\| w \\| _1 = \\sum |w_i|$$\n",
        "* [ElasticNet](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html#sklearn.linear_model.ElasticNet): Combina ambas anteriores.\n",
        "\n",
        "En esto caso, sólo experimentaremos con la primera y veremos:\n",
        "\n",
        "1. El efecto en la norma de los coeficientes.\n",
        "2. El efecto en el rendimiento de la tarea de regresión.\n",
        "\n",
        "En notebooks posteriores analizaremos un poco más a fondo la regularización."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvnQWLDr93WZ"
      },
      "source": [
        "Repetimos el procedimiento, ya de forma más compacta:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SZfSUKKkYdmg"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "url = 'https://github.com/DCDPUAEM/DCDP/raw/main/03%20Machine%20Learning/data/cars-prices.csv'\n",
        "df = pd.read_csv(url)\n",
        "df.drop(columns=['car_ID','CarName'],inplace=True)\n",
        "cols = ['cylindernumber','doornumber']\n",
        "replacing_dict = {'four':4, 'six':6, 'five':5, 'three':3, 'twelve':12, 'two':2, 'eight':8}\n",
        "\n",
        "for col in cols:\n",
        "    df[col].replace(replacing_dict,inplace=True)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vspzaU2JY0x6"
      },
      "outputs": [],
      "source": [
        "y = df['price'].values\n",
        "\n",
        "df.drop(columns='price',inplace=True)\n",
        "X_df = pd.get_dummies(df)\n",
        "X_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yiIWCsVQ-yR3"
      },
      "outputs": [],
      "source": [
        "X = X_df.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A6TBsAmGZBnY"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, train_size=0.8, random_state=4595)\n",
        "\n",
        "print(f\"Entrenamiento: {X_train.shape,y_train.shape}\")\n",
        "print(f\"Prueba: {X_test.shape,y_test.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3aU3Kf5p-8Mp"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_selection import VarianceThreshold\n",
        "\n",
        "selector = VarianceThreshold()\n",
        "X_train = selector.fit_transform(X_train)   # Entrenamos y transformamos el de entrenamiento\n",
        "X_test = selector.transform(X_test)        # Sólo transformamos el de prueba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0CrfyH9OY9vL"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "# scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eUCybDwIZIFF"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "lr = Ridge(alpha=2)\n",
        "lr.fit(X_train,y_train)\n",
        "\n",
        "print(f\"Entrenamiento: {lr.score(X_train,y_train)}\")\n",
        "print(f\"Prueba: {lr.score(X_test,y_test)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CpZKP4WsZiZr"
      },
      "outputs": [],
      "source": [
        "columns = X_df.columns.to_list()\n",
        "coefs_dict = dict(zip(columns,lr.coef_))\n",
        "dict(sorted(coefs_dict.items(),key=lambda x:x[1],reverse=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JJ4lL1edsC4"
      },
      "source": [
        "¿Qué efecto tiene el parámetro $\\alpha$ sobre la magnitud de los coeficientes?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0kgxYigjdrlQ"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "alphas = np.logspace(-12,0,num=10)\n",
        "normas = []\n",
        "\n",
        "for alpha in alphas:\n",
        "    lr = Ridge(alpha=alpha)\n",
        "    lr.fit(X_train,y_train)\n",
        "    normas.append(np.mean(np.abs(lr.coef_)))\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(alphas,normas)\n",
        "plt.xlabel(\"alpha\")\n",
        "plt.ylabel(\"Norma promedio\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZo0bkkRbFkF"
      },
      "source": [
        "¿Qué efecto tiene el parámetro $\\alpha$ en el score?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jaAojk0VZ56J"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "alphas = np.logspace(-10,0,num=10)\n",
        "train_scores = []\n",
        "test_scores = []\n",
        "\n",
        "for alpha in alphas:\n",
        "    lr = Ridge(alpha=alpha)\n",
        "    lr.fit(X_train,y_train)\n",
        "    train_scores.append(lr.score(X_train,y_train))\n",
        "    test_scores.append(lr.score(X_test,y_test))\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(alphas,train_scores,label=\"Train\")\n",
        "plt.plot(alphas,test_scores,label=\"Test\")\n",
        "plt.xlabel(\"alpha\")\n",
        "plt.ylabel(\"score\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdKwtizBchJe"
      },
      "source": [
        "Como podemos ver, en este ejemplo concreto, la regularización no beneficia al problema en cuestión de la métrica de rendimiento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apVBBVhOTnnw"
      },
      "source": [
        "#⭕ Ejercicio\n",
        "\n",
        "Usaremos un dataset sobre publicidad. Este dataset consta de 200 registros, cada registro consta de las variables.\n",
        "\n",
        "* TV: dólares de publicidad gastados en TV para un solo producto en un mercado determinado (en miles de dólares)\n",
        "* Radio: inversión publicitaria en radio\n",
        "* Newspaper: inversión publicitaria en periódicos\n",
        "* Sales: ventas de un solo producto en un mercado determinado (en miles de unidades).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qeCumkNlT_ds"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "url = 'https://github.com/DCDPUAEM/DCDP/raw/main/03%20Machine%20Learning/data/advertising.csv'\n",
        "df = pd.read_csv(url,index_col=0)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4jD08YrJ4hWr"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sns.pairplot(df, x_vars=['TV','Radio','Newspaper'], y_vars='Sales', height=5, aspect=1, kind='reg')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BqNvUwqQ9O9e"
      },
      "source": [
        "Objetivos:\n",
        "\n",
        "1. Entrenar un modelo de regresión lineal usando el 85% de las instancias, separar el resto para prueba. **No olvides el preprocesamiento**, **cuidado con el data leakage**.\n",
        "2. Reportar las métricas de rendimiento MAE, MSE en las predicciones con el conjunto de prueba solamente.\n",
        "3. Con base en la métrica de rendimiento MAE, escoge el mejor modelo de regresión lineal. Es decir, ¿cuál es el menor MAE que puedes obtener en el conjunto de prueba? Junto con este número, reporta los parámetros y la combinación de técnicas que usaste.\n",
        "\n",
        "Considera las siguientes situaciones en el preprocesamiento:\n",
        "\n",
        "* ¿Hay valores faltantes? En caso de que sí, recuerda que tienes dos opciones: remover estas instancias o hacer imputación.\n",
        "* ¿Cuál es el rango de las 3 variables? ¿tienen magnitudes muy diferentes?\n",
        "* ¿Hay alguna variable que consideres que no es muy relevante?\n",
        "* Realiza la(s) técnica(s) de normalización que consideres necesario: selección de features, normalización.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uyxln7Cd8ltU"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

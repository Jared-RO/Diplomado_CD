{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/DCDPUAEM/DCDP/blob/main/04%20Deep%20Learning/notebooks/Practica-2-CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ],
      "metadata": {
        "id": "CuzGO02BJbmv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Práctica 2</h1>\n",
        "\n",
        "<h2>Redes CNN</h2>\n",
        "\n",
        "Continuaremos con el trábado en el dataset Fashion MNIST.\n",
        "\n",
        "<img align=\"center\" width=\"50%\" src=\"https://github.com/DCDPUAEM/DCDP/blob/main/04%20Deep%20Learning/img/Fashion-MNIST.jpg?raw=1\"/>\n",
        "\n",
        "[Más información sobre el dataset](https://keras.io/api/datasets/fashion_mnist/)"
      ],
      "metadata": {
        "id": "RxqspH627xDx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "24FpDZgIktFn"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import fashion_mnist\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "#-------- Dataset --------\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "print(f\"X_train shape: {x_train.shape}\")\n",
        "print(f\"y_train shape: {y_train.shape}\")\n",
        "print(f\"X_test shape: {x_test.shape}\")\n",
        "print(f\"y_test shape: {y_test.shape}\")\n",
        "\n",
        "#-------- Reescalamiento --------\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "#-------- Codificación vectores de clase --------\n",
        "print(f\"y_train shape (valores de clase):\\n{y_train.shape}\")\n",
        "num_classes = 10\n",
        "y_train = to_categorical(y_train,num_classes)\n",
        "y_test = to_categorical(y_test,num_classes)\n",
        "print(f\"y_train shape (vectores de clase):\\n{y_train.shape}\")\n",
        "\n",
        "#-------- Reshape para incluir el número de canales de la imágen --------\n",
        "print(f\"x_train shape (antes):\\n{x_train.shape}\")\n",
        "x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], x_train.shape[2], 1))\n",
        "x_test = x_test.reshape((x_test.shape[0], x_test.shape[1], x_test.shape[2], 1))\n",
        "print(f\"x_train shape (después):\\n{x_train.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Función para graficar las curvas de entrenamiento\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def graficar_curvas(history):\n",
        "    fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
        "    axs[0].plot(history.history['loss'],label='Training')\n",
        "    axs[0].plot(history.history['val_loss'],label='Validation')\n",
        "    axs[0].set_title('Loss')\n",
        "    axs[0].legend()\n",
        "    axs[1].plot(history.history['accuracy'],label='Training')\n",
        "    axs[1].plot(history.history['val_accuracy'],label='Validation')\n",
        "    axs[1].set_title('Accuracy')\n",
        "    axs[1].legend()\n",
        "    fig.show()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Rv9_tjDjhJ6R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recordemos el rendimiento de los algoritmos de Machine Learning clásico:\n",
        "\n",
        "<img align=\"center\" width=\"40%\" src=\"https://github.com/DCDPUAEM/DCDP/blob/main/04%20Deep%20Learning/img/ML-Fashion-Mnist.png?raw=1\"/>"
      ],
      "metadata": {
        "id": "O-vW2gnVcDlp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El modelo básico trabajado en clase"
      ],
      "metadata": {
        "id": "QtzOtyFtbZ2w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(filters=16,kernel_size=3,activation='relu',\n",
        "                padding=\"same\", strides=1,\n",
        "                 input_shape=(x_train.shape[1], x_train.shape[2], 1)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(50, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "lVXrMhDhlQuu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit( ) # Completar\n",
        "\n",
        "graficar_curvas(history) # Graficar las curvas de entrenamiento"
      ],
      "metadata": {
        "id": "ZwGKdlGIfTte"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "⭕ Práctica\n",
        "\n",
        "Usando el mismo dataset, implementa las siguientes redes CNN usando como punto de partida la red que hemos implementado, ya sea la versión como función o la *normal* (si te sientes insegura/o respecto a la implementación, no uses el enfoque de función):\n",
        "\n",
        "* Una red CNN con dos capas convolucionales, en lugar de uno. La segunda capa tendrá las siguientes especificaciones:\n",
        " * Una capa convolucional 2D de 8 filtros, el resto de hiperparámetros serán los mismos.\n",
        " * Una capa de MaxPooling.\n",
        "* La red CNN anterior, con las mismas dos capas convolucionales. Cambia la función de activación por `tanh`. ¿Cómo cambian los resultados?\n",
        "* La red CNN anterior, con las mismas dos capas convolucionales. Cambia el hiperparámetro `padding='valid'`. ¿Qué observas?\n",
        "* La red CNN anterior, con las mismas dos capas convolucionales. En la parte MLP de la red, agrega 3 capas densas. Usa el número de neuronas en estas capas de tu elección, así como la función de activación en ellas. Experimenta un poco.\n",
        "* Una red CNN con una capa convolucional con 32 filtros, la parte MLP tendrá un capa oculta de 100 neuronas con activación `relu`. Para el optimizador una un [`SGD`](https://keras.io/api/optimizers/sgd/) con tasa de aprendizaje $0.01$.\n"
      ],
      "metadata": {
        "id": "mAWDu3nA9CXP"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9Y2HDNbav8HU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Implementa una red MLP para este mismo problema. Prueba al menos 3 arquitecturas diferentes, ¿cuál fue la mejor opción? ¿cómo se compara con una CNN?\n",
        " * No olvides el conjunto de validación.\n",
        " * Usa el callback de `EarlyStopping`.\n",
        " * Cuida no re-entrenar modelos.\n",
        "\n",
        "Para este último punto, usa el siguiente código para preparar el dataset:"
      ],
      "metadata": {
        "id": "m94tWDV3g1HW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import fashion_mnist\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "print(\"Shapes al cargar el dataset:\")\n",
        "print(f\"X train shape: {X_train.shape}\")\n",
        "print(f\"y train shape: {y_train.shape}\")\n",
        "print(f\"X test shape: {X_test.shape}\")\n",
        "print(f\"y test shape: {y_test.shape}\")\n",
        "\n",
        "num_classes = 10\n",
        "y_train = to_categorical(y_train, num_classes)\n",
        "y_test = to_categorical(y_test, num_classes)\n",
        "\n",
        "X_train = X_train.astype('float32') / 255.0\n",
        "X_test = X_test.astype('float32') / 255.0\n",
        "\n",
        "X_train = X_train.reshape(-1, 784)\n",
        "X_test = X_test.reshape(-1, 784)\n",
        "\n",
        "print(\"\\nShapes al preprocesar el dataset:\")\n",
        "print(f\"X train shape: {X_train.shape}\")\n",
        "print(f\"y train shape: {y_train.shape}\")\n",
        "print(f\"X test shape: {X_test.shape}\")\n",
        "print(f\"y test shape: {y_test.shape}\")"
      ],
      "metadata": {
        "id": "06A7gTR6g1qB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZHWPcXcXzwkl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dudas: mauricio.toledo@unison.mx"
      ],
      "metadata": {
        "id": "EH_tiE8Qif8h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Respecto a las dimensiones de salida de una capa convolucional: [wikipedia](https://en.wikipedia.org/wiki/Convolutional_neural_network#Convolutional_layer), [stackoverflow](https://stackoverflow.com/questions/53580088/calculate-the-output-size-in-convolution-layer)."
      ],
      "metadata": {
        "id": "vS644W0EfICG"
      }
    }
  ]
}
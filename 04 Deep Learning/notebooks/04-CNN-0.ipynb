{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/DCDPUAEM/DCDP/blob/main/04%20Deep%20Learning/notebooks/04-CNN-0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ],
      "metadata": {
        "id": "CuzGO02BJbmv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Convolutional Neural Networks\n",
        "\n",
        "En esta notebook implementamos un ejemplo sencillo de una red CNN para el dataset de Fashion MNIST.\n",
        "\n",
        "<img align=\"center\" width=\"50%\" src=\"https://github.com/DCDPUAEM/DCDP/blob/main/04%20Deep%20Learning/img/Fashion-MNIST.jpg?raw=1\"/>\n",
        "\n",
        "* [Más información sobre el dataset](https://keras.io/api/datasets/fashion_mnist/)\n",
        "* [Benchmarks](https://paperswithcode.com/sota/image-classification-on-fashion-mnist) en este dataset."
      ],
      "metadata": {
        "id": "RxqspH627xDx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "24FpDZgIktFn"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import fashion_mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "print(f\"X_train shape: {x_train.shape}\")\n",
        "print(f\"y_train shape: {y_train.shape}\")\n",
        "print(f\"X_test shape: {x_test.shape}\")\n",
        "print(f\"y_test shape: {y_test.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hacemos reescalimiento para tener los valores de intensidad de los pixeles como valores $0\\leq x_i \\leq 1$:"
      ],
      "metadata": {
        "id": "iKvm1KkpPWEM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0"
      ],
      "metadata": {
        "id": "1M45Aisl4-nj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Al ser clasificación multiclase tenemos que codificar los valores de clases a vectores de etiqueta:"
      ],
      "metadata": {
        "id": "_PRXoDG7Pjrv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import to_categorical\n",
        "\n",
        "print(f\"y_train shape (valores de clase):\\n{y_train.shape}\")\n",
        "num_classes = 10\n",
        "y_train = to_categorical(y_train,num_classes)\n",
        "y_test = to_categorical(y_test,num_classes)\n",
        "print(f\"y_train shape (vectores de clase):\\n{y_train.shape}\")"
      ],
      "metadata": {
        "id": "ZsUVYQjAtsLq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hacemos el reshape para incluir la información sobre el número de canales:"
      ],
      "metadata": {
        "id": "0DMusXMqPpBI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"x_train shape (antes):\\n{x_train.shape}\")\n",
        "x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], x_train.shape[2], 1))\n",
        "x_test = x_test.reshape((x_test.shape[0], x_test.shape[1], x_test.shape[2], 1))\n",
        "print(f\"x_train shape (después):\\n{x_train.shape}\")"
      ],
      "metadata": {
        "id": "w4X0LknwqM1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Función para graficar las curvas de entrenamiento\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def graficar_curvas(history):\n",
        "    fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
        "    axs[0].plot(history.history['loss'],label='Training')\n",
        "    axs[0].plot(history.history['val_loss'],label='Validation')\n",
        "    axs[0].set_title('Loss')\n",
        "    axs[0].legend()\n",
        "    axs[1].plot(history.history['accuracy'],label='Training')\n",
        "    axs[1].plot(history.history['val_accuracy'],label='Validation')\n",
        "    axs[1].set_title('Accuracy')\n",
        "    axs[1].legend()\n",
        "    fig.show()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Rv9_tjDjhJ6R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definimos un primer modelo de CNN. Usaremos las capas `Conv2D` para las operaciones de convolución y `MaxPooling2D` para el pooling.\n",
        "\n",
        "* https://keras.io/api/layers/convolution_layers/convolution2d/\n",
        "* https://keras.io/api/layers/pooling_layers/max_pooling2d/"
      ],
      "metadata": {
        "id": "IeeWdbVwRy0V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos definir el modelo Sequential como usualmente lo hacemos:"
      ],
      "metadata": {
        "id": "QtzOtyFtbZ2w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from keras.models import Sequential\n",
        "# from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout\n",
        "\n",
        "# model = Sequential()\n",
        "# model.add(Conv2D(filters=16,kernel_size=3,activation='relu',\n",
        "#                 padding=\"same\", strides=1,\n",
        "#                  input_shape=(x_train.shape[1], x_train.shape[2], 1)))\n",
        "# model.add(MaxPooling2D((2, 2)))\n",
        "# model.add(Flatten())\n",
        "# model.add(Dense(50, activation='relu'))\n",
        "# # model.add(Dropout(0.1))\n",
        "# model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# model.summary()\n",
        "\n",
        "# model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "lVXrMhDhlQuu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "O podemos definirlo por medio de una función, que nos permite generar modelos diferentes de forma rápida. Además, de esta manera nos aseguramos de tener modelos *en blanco*, listos para ser entrenados."
      ],
      "metadata": {
        "id": "jRCuDGUDbfOA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout\n",
        "\n",
        "def build_model(num_filtros=16,num_neuronas_densas=[50], dropout=False,\n",
        "                optimizador='adam'):\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(filters=num_filtros,kernel_size=3,activation='relu',\n",
        "                        padding=\"same\", strides=1,\n",
        "                        input_shape=(x_train.shape[1], x_train.shape[2], 1)))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Flatten())\n",
        "    if num_neuronas_densas is not None:\n",
        "        for k in num_neuronas_densas:\n",
        "            model.add(Dense(k, activation='relu'))\n",
        "            if dropout:\n",
        "                model.add(Dropout(0.1))\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "    model.compile(optimizer=optimizador, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "jAyIKrOsPx6W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model()\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "mp4dk21IQZYk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3)"
      ],
      "metadata": {
        "id": "dB_p2xeEzkPd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x_train, y_train, epochs=30, validation_split=0.2,callbacks=[early_stopping])"
      ],
      "metadata": {
        "id": "3FAsOH-Sqwku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "id": "XMf5FSrwqz0N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graficar_curvas(history)"
      ],
      "metadata": {
        "id": "D94m_SxqfPoA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recordemos el rendimiento de los algoritmos de Machine Learning clásico:\n",
        "\n",
        "<img align=\"center\" width=\"40%\" src=\"https://github.com/DCDPUAEM/DCDP/blob/main/04%20Deep%20Learning/img/ML-Fashion-Mnist.png?raw=1\"/>"
      ],
      "metadata": {
        "id": "O-vW2gnVcDlp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos entrenar nuevos modelos de forma muy rápida usando la función para generar los modelos:"
      ],
      "metadata": {
        "id": "56kB1OTDaOHV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.optimizers import Adadelta\n",
        "\n",
        "#  Efecto de un optimizador en el entrenamiento y rendimiento\n",
        "\n",
        "# Optimizador lento/malo para este ejemplo:\n",
        "opt = Adadelta(learning_rate=0.0005)"
      ],
      "metadata": {
        "id": "koRIkHu8CubL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model(num_filtros=4,num_neuronas_densas=None,optimizador='SGD')\n",
        "model.summary()\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
        "history = model.fit(x_train, y_train, epochs=30, validation_split=0.2,callbacks=[early_stopping])\n",
        "print(\"Evaluación en el conjunto de prueba:\")\n",
        "model.evaluate(x_test, y_test)[1]"
      ],
      "metadata": {
        "id": "cDFhz1yVbRex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graficar_curvas(history)"
      ],
      "metadata": {
        "id": "ZwGKdlGIfTte"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Probemos estas combinaciones:\n",
        "\n",
        "* 16 | 50 | 10\n",
        "* 8 | 50 con y sin dropout | 10\n",
        "* 32 | 100 10 | 10\n",
        "* 64 | 100 100 | 10\n",
        "* 16 | - | 10"
      ],
      "metadata": {
        "id": "j9TBb6O8fa4X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "⭕ Práctica\n",
        "\n",
        "Usando el mismo dataset, implementa las siguientes redes CNN usando como punto de partida la red que hemos implementado, ya sea la versión como función o la *normal* (si te sientes insegura/o respecto a la implementación, no uses el enfoque de función):\n",
        "\n",
        "* Una red CNN con dos capas convolucionales, en lugar de uno. La segunda capa tendrá las siguientes especificaciones:\n",
        " * Una capa convolucional 2D de 8 filtros, el resto de hiperparámetros serán los mismos.\n",
        " * Una capa de MaxPooling.\n",
        "* La red CNN anterior, con las mismas dos capas convolucionales. Cambia la función de activación por `tanh`. ¿Cómo cambian los resultados?\n",
        "* La red CNN anterior, con las mismas dos capas convolucionales. Cambia el hiperparámetro `padding='valid'`. ¿Qué observas?\n",
        "* La red CNN anterior, con las mismas dos capas convolucionales. En la parte MLP de la red, agrega 3 capas densas. Usa el número de neuronas en estas capas de tu elección, así como la función de activación en ellas. Experimenta un poco.\n",
        "* Una red CNN con una capa convolucional con 32 filtros, la parte MLP tendrá un capa oculta de 100 neuronas con activación `relu`. Para el optimizador una un [`SGD`](https://keras.io/api/optimizers/sgd/) con tasa de aprendizaje $0.01$.\n"
      ],
      "metadata": {
        "id": "mAWDu3nA9CXP"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9Y2HDNbav8HU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Implementa una red MLP para este mismo problema. Prueba al menos 3 arquitecturas diferentes, ¿cuál fue la mejor opción? ¿cómo se compara con una CNN?\n",
        " * No olvides el conjunto de validación.\n",
        " * Usa el callback de `EarlyStopping`.\n",
        " * Cuida no re-entrenar modelos.\n",
        "\n",
        "Para este último punto, usa el siguiente código para preparar el dataset:"
      ],
      "metadata": {
        "id": "m94tWDV3g1HW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import fashion_mnist\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "print(\"Shapes al cargar el dataset:\")\n",
        "print(f\"X train shape: {X_train.shape}\")\n",
        "print(f\"y train shape: {y_train.shape}\")\n",
        "print(f\"X test shape: {X_test.shape}\")\n",
        "print(f\"y test shape: {y_test.shape}\")\n",
        "\n",
        "num_classes = 10\n",
        "y_train = to_categorical(y_train, num_classes)\n",
        "y_test = to_categorical(y_test, num_classes)\n",
        "\n",
        "X_train = X_train.astype('float32') / 255.0\n",
        "X_test = X_test.astype('float32') / 255.0\n",
        "\n",
        "X_train = X_train.reshape(-1, 784)\n",
        "X_test = X_test.reshape(-1, 784)\n",
        "\n",
        "print(\"\\nShapes al preprocesar el dataset:\")\n",
        "print(f\"X train shape: {X_train.shape}\")\n",
        "print(f\"y train shape: {y_train.shape}\")\n",
        "print(f\"X test shape: {X_test.shape}\")\n",
        "print(f\"y test shape: {y_test.shape}\")"
      ],
      "metadata": {
        "id": "06A7gTR6g1qB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dudas: mauricio.toledo@unison.mx"
      ],
      "metadata": {
        "id": "EH_tiE8Qif8h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Respecto a las dimensiones de salida de una capa convolucional: [wikipedia](https://en.wikipedia.org/wiki/Convolutional_neural_network#Convolutional_layer), [stackoverflow](https://stackoverflow.com/questions/53580088/calculate-the-output-size-in-convolution-layer)."
      ],
      "metadata": {
        "id": "vS644W0EfICG"
      }
    }
  ]
}
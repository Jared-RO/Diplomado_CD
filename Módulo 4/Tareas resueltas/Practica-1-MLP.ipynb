{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCYJbEwVkjda"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DCDPUAEM/DCDP/blob/main/04%20Deep%20Learning/notebooks/Practica-1-MLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFJ63s_YhFD7"
      },
      "source": [
        "✅ Conectar la notebook en modo GPU\n",
        "\n",
        "Entorno de ejecución → Cambiar tipo de entorno de ejecución\n",
        "\n",
        "Algunas consideraciones:\n",
        "\n",
        "* No dejar la notebook conectada sin actividad ya que Colab penaliza esto al asignar un entorno con GPU.\n",
        "* No pedir el entorno con GPU si no se va a usar."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDSCKhUMkOUL"
      },
      "source": [
        "---\n",
        "\n",
        "# ⭕ Parte I\n",
        "\n",
        "Usando el mismo dataset MNIST de Keras, implementa las siguientes redes neuronales de tipo MLP:\n",
        "\n",
        "* 1 capa oculta de 200 neuronas sin activación. Entrena durante 30 épocas.\n",
        "* 1 capa oculta de 200 neuronas con activación $tanh$. Entrena durante 30 épocas.\n",
        "* 3 capas ocultas de 100, 200 y 100 neuronas respectivamente, todas con activación ReLU. Entrena durante 50 épocas.\n",
        "\n",
        "En cada uno de los experimentos determina las especificaciones de las capas de entrada y salida. Además, en cada caso, reporta el accuracy y recall en el conjunto de prueba, así como las curvas de entrenamiento (perdida y accuracy).\n",
        "\n",
        "* Con el objetivo de subir la métrica de accuracy en el conjunto de prueba, entrena un nuevo módelo de red neuronal MLP cambiando los siguientes hiperparámetros:\n",
        "\n",
        " * Número de capas ocultas.\n",
        " * Número de neuronas en cada capa oculta.\n",
        " * Función de activación de cada capa oculta.\n",
        " * Optimizador ([opciones](https://keras.io/api/optimizers/)).\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Como referencia, el mejor resultado hasta ahora, sin usar redes convolucionales, es un accuracy de 99.65% (https://arxiv.org/abs/1003.0358)\n",
        "\n",
        "Lista de resultados: http://yann.lecun.com/exdb/mnist/, https://paperswithcode.com/sota/image-classification-on-mnist"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSNvVbZvza2o"
      },
      "source": [
        "## El conjunto de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GZUuquv7za2u"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train shape: (60000, 28, 28)\n",
            "y_train shape: (60000,)\n",
            "X_test shape: (10000, 28, 28)\n",
            "y_test shape: (10000,)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"y_train shape: {y_train.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}\")\n",
        "print(f\"y_test shape: {y_test.shape}\")\n",
        "\n",
        "y_test_original = y_test.copy()  # Esta copia la usarás para hacer las evaluaciones de las métricas de rendimiento\n",
        "\n",
        "y_train = to_categorical(y_train,num_classes=10)\n",
        "y_test = to_categorical(y_test,num_classes=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TBBNLUG4vWq"
      },
      "source": [
        "## Tu trabajo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "khLCGTnUz9ev"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEZGlYCiz9xm"
      },
      "source": [
        "# ⭕ Parte II"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWAn3u8giOxG"
      },
      "source": [
        "Tomando como referencia la [notebook](https://github.com/DCDPUAEM/DCDP/blob/main/04%20Deep%20Learning/notebooks/02-MLP-Regresion.ipynb) de MLP para regresión, realiza las siguientes tareas. En las primeras 5 tareas el objetivo es experimentar y reflexionar sobre el efecto de distintos aspectos del entrenamiento en el rendimiento del modelo.\n",
        "\n",
        "1. Repite el entrenamiendo del modelo usando 100 épocas **sin normalizar los datos**, ¿qué le sucede a las métricas de rendimiento y curvas de entrenamiento?\n",
        "\n",
        "2. Repite el entrenamiendo del modelo usando 100 épocas, normalización de los datos y **con alguna función de activación en la capa de salida (tanh o sigmoide)**, ¿qué le sucede a las métricas de rendimiento y curvas de entrenamiento?\n",
        "\n",
        "4. Repite el entrenamiendo del modelo usando 100 épocas, normalización de los datos y **con la función de activación ReLU en la capa de salida**, ¿qué le sucede a las métricas de rendimiento y curvas de entrenamiento?\n",
        "\n",
        "5. Comprueba el modelo que entrenamos en la notebook (con 100 épocas, normalización y sin función de activación en la salida) con los siguientes algoritmos de ML clásico:\n",
        " * Regresión Lineal\n",
        " * Regresión Polinomial\n",
        " * Regresor KNN\n",
        " Comprueba los modelos usando MAE en el conjunto de prueba. ¿Cuál tuvo mejor desempeño?  \n",
        "\n",
        "El objetivo en la siguiente tarea es experimentar para encontrar un mejor modelo que suba las métricas de rendimiento del modelo. **Cuidado con el overfitting.**\n",
        "\n",
        "5. Usando los datos normalizados, prueba con diferentes combinaciones de los parámetros del módelo:\n",
        "    * Número de capas ocultas\n",
        "    * Número de nueronas en las capas ocultas\n",
        "    * Funciones de activación de las capas ocultas\n",
        "    * Optimizador y tasa de entrenamiento\n",
        "\n",
        " Puedes hacer el modelo más sencillo o más complejo. Reporta la combinación de parámetros que produjo el mejor resultado.\n",
        "\n",
        "En esta última tarea probaras cómo es recibir nuevos datos para realizar predicciones con tu mejor modelo que hayas obtenido.\n",
        "\n",
        "6. Ya que tengas tu mejor modelo, toma el archivo `mpg_new_data.csv` del repositorio y obten las predicciones para estos datos. Compararemos contra los valores reales. **Guarda estas predicciones en un archivo CSV, que también adjuntarás en la entrega de la actividad**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cPjHbyz4rIV"
      },
      "source": [
        "## El conjunto de datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60ck-VT81L80"
      },
      "source": [
        "Cargamos, limpiamos y separamos los datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SIbe9TIm0AW3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/DCDPUAEM/DCDP/main/04%20Deep%20Learning/data/auto-mpg.data\"\n",
        "\n",
        "df = pd.read_csv(url,\n",
        "                header=0,\n",
        "                index_col=0,\n",
        "                na_values = \"?\",\n",
        "                comment='\\t',\n",
        "                skipinitialspace=True)\n",
        "\n",
        "df = df.dropna()\n",
        "df = pd.get_dummies(data=df,columns=['Origin'],\n",
        "                       drop_first=True,dtype=int)\n",
        "df.rename(columns={'Origin_2':'Europe',\n",
        "                   'Origin_3':'Japan'},\n",
        "             inplace=True)\n",
        "display(df)\n",
        "\n",
        "X = df.iloc[:,1:].values\n",
        "y = df['MPG'].values\n",
        "\n",
        "print(f\"Shapes de X y y: {X.shape}, {y.shape}\")\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,train_size=0.85,random_state=189)\n",
        "\n",
        "print(f\"Train size: {X_train.shape[0]}\")\n",
        "print(f\"Test size: {X_test.shape[0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydtCRy8A4tQU"
      },
      "source": [
        "## Tu trabajo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P6gNkV320gCs"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
